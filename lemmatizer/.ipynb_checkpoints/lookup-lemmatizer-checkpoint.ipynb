{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "#train_file = sys.argv[1]\n",
    "#test_file = sys.argv[2]\n",
    "\n",
    "train_file = \"UD_Hindi-HDTB-master/hi_hdtb-ud-train.conllu\"\n",
    "test_file = \"UD_Hindi-HDTB-master/hi_hdtb-ud-test.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counters for lemmas in the training data: word form -> lemma -> count\n",
    "lemma_count = {}\n",
    "\n",
    "# Lookup table learned from the training data: word form -> lemma\n",
    "lemma_max = {}\n",
    "\n",
    "# Variables for reporting results\n",
    "training_stats = ['Wordform types' , 'Wordform tokens' , 'Unambiguous types' , \n",
    "                  'Unambiguous tokens' , 'Ambiguous types' , 'Ambiguous tokens' , \n",
    "                  'Ambiguous most common tokens' , 'Identity tokens']\n",
    "\n",
    "training_counts = dict.fromkeys(training_stats , 0)\n",
    "\n",
    "test_outcomes = ['Total test items' , 'Found in lookup table' , 'Lookup match' , \n",
    "                 'Lookup mismatch' , 'Not found in lookup table' , 'Identity match' , \n",
    "                 'Identity mismatch']\n",
    "\n",
    "test_counts = dict.fromkeys(test_outcomes , 0)\n",
    "\n",
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training: read training data and populate lemma counters\n",
    "train_data = open(train_file , 'r', encoding='utf8')\n",
    "\n",
    "for line in train_data:\n",
    "    \n",
    "    # Tab character identifies lines containing tokens\n",
    "    if re.search ('\\t' , line):\n",
    "\n",
    "        # Tokens represented as tab-separated fields\n",
    "        field = line.strip().split('\\t')\n",
    "\n",
    "        # Word form in second field, lemma in third field\n",
    "        form = field[1]\n",
    "        lemma = field[2]\n",
    "        \n",
    "        if form == lemma:\n",
    "            training_counts['Identity tokens'] += 1\n",
    "        \n",
    "        training_counts['Wordform tokens'] += 1\n",
    "                \n",
    "        if form in lemma_count:\n",
    "            #for that particular form, check all lemmas and increment count for the right one\n",
    "            arr = lemma_count[form]\n",
    "            exist = False\n",
    "            for idx in range(len(arr)):\n",
    "                if arr[idx][0] == lemma:\n",
    "                    arr[idx][1] += 1\n",
    "                    exist = True\n",
    "            #if that lemma doesnt exist, append\n",
    "            if not exist:\n",
    "                arr.append([lemma, 1])\n",
    "        else:\n",
    "            lemma_count[form] = [[lemma, 1]]\n",
    "            training_counts['Wordform types'] += 1\n",
    "            \n",
    "#print({key: value for key, value in sorted(lemma_count.items(), key=lambda item: item[1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model building and training statistics\n",
    "for form in lemma_count.keys():\n",
    "    \n",
    "    #non-ambigous ones have len of only 1\n",
    "    arr = lemma_count[form]\n",
    "    if len(arr) == 1:\n",
    "        training_counts['Unambiguous types'] += 1\n",
    "        training_counts['Unambiguous tokens'] += arr[0][1]\n",
    "        lemma_max[form] = arr[0][0]\n",
    "    else:\n",
    "        training_counts['Ambiguous types'] += 1\n",
    "        max_idx = 0\n",
    "        max_val = 0\n",
    "        for i in range(len(arr)):\n",
    "            training_counts['Ambiguous tokens'] += arr[i][1]\n",
    "            if arr[i][1] > max_val:\n",
    "                max_val = arr[i][1]\n",
    "                max_idx = i\n",
    "        lemma_max[form] = arr[max_idx][0]\n",
    "        training_counts['Ambiguous most common tokens'] += arr[max_idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['Expected lookup'] = (training_counts['Unambiguous tokens']+training_counts['Ambiguous most common tokens'])/training_counts['Wordform tokens']\n",
    "\n",
    "accuracies['Expected identity'] = training_counts['Identity tokens']/training_counts['Wordform tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing: read test data, and compare lemmatizer output to actual lemma\n",
    "test_data = open (test_file, 'r', encoding='utf8')\n",
    "\n",
    "for line in test_data:\n",
    "\n",
    "    # Tab character identifies lines containing tokens\n",
    "    if re.search ('\\t' , line):\n",
    "\n",
    "        # Tokens represented as tab-separated fields\n",
    "        field = line.strip().split('\\t')\n",
    "\n",
    "        # Word form in second field, lemma in third field\n",
    "        form = field[1]\n",
    "        lemma = field[2]\n",
    "\n",
    "        test_counts['Total test items'] += 1\n",
    "        \n",
    "        if form in lemma_max:\n",
    "            test_counts['Found in lookup table'] += 1\n",
    "            if lemma_max[form] == lemma:\n",
    "                test_counts['Lookup match'] += 1\n",
    "            else:\n",
    "                test_counts['Lookup mismatch'] += 1\n",
    "        else:\n",
    "            test_counts['Not found in lookup table'] += 1\n",
    "            if form == lemma:\n",
    "                test_counts['Identity match'] += 1\n",
    "            else:\n",
    "                test_counts['Identity mismatch'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Total test items': 35430,\n",
       " 'Found in lookup table': 33849,\n",
       " 'Lookup match': 32628,\n",
       " 'Lookup mismatch': 1221,\n",
       " 'Not found in lookup table': 1581,\n",
       " 'Identity match': 1227,\n",
       " 'Identity mismatch': 354}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies['Lookup'] = test_counts['Lookup match']/test_counts['Found in lookup table']\n",
    "\n",
    "accuracies['Identity'] = test_counts['Identity match']/test_counts['Not found in lookup table']\n",
    "\n",
    "accuracies['Overall'] = (test_counts['Lookup match']+test_counts['Identity match'])/test_counts['Total test items']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Expected lookup': 0.9673162383431119,\n",
       " 'Expected identity': 0.7168830521922599,\n",
       " 'Lookup': 0.9639280333244704,\n",
       " 'Identity': 0.7760910815939279,\n",
       " 'Overall': 0.9555461473327689}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
